{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsurusekazuki/.pyenv/versions/3.6.0/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1775.15 MB\n",
      "Memory usage after optimization is: 489.41 MB\n",
      "Decreased by 72.4%\n",
      "Memory usage of dataframe is 1519.24 MB\n",
      "Memory usage after optimization is: 427.17 MB\n",
      "Decreased by 71.9%\n",
      "CPU times: user 5min 32s, sys: 5min 9s, total: 10min 41s\n",
      "Wall time: 11min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_transaction = pd.read_csv('../../data/input/train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('../../data/input/test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "\n",
    "train_transaction = reduce_mem_usage(train_transaction)\n",
    "test_transaction = reduce_mem_usage(test_transaction)\n",
    "\n",
    "sample_submission = pd.read_csv('../../data/input/sample_submission.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction['hour'] = train_transaction['TransactionDT'].map(lambda x:(x//3600)%24)\n",
    "test_transaction['hour'] = test_transaction['TransactionDT'].map(lambda x:(x//3600)%24)\n",
    "train_transaction['weekday'] = train_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)\n",
    "test_transaction['weekday'] = test_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"TransactionDT,TransactionAmt,ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,M1,M2,M3,M4,M5,M6,M7,M8,M9\".split(\",\")\n",
    "train_test = train_transaction[cols].append(test_transaction[cols])\n",
    "\n",
    "for col in \"ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14\".split(\",\"):\n",
    "    col_count = train_test.groupby(col)['TransactionDT'].count()\n",
    "    train_transaction[col+'_count'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_count'] = test_transaction[col].map(col_count)\n",
    "#     print(col,test_transaction[col].map(lambda x:0 if x in s else 1).sum())\n",
    "\n",
    "\n",
    "for col in \"card1,card2,card5,addr1,addr2\".split(\",\"):\n",
    "    col_count = train_test.groupby(col)['TransactionAmt'].mean()\n",
    "    train_transaction[col+'_amtcount'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_amtcount'] = test_transaction[col].map(col_count)\n",
    "    col_count1 = train_test[train_test['C5'] == 0].groupby(col)['C5'].count()\n",
    "    col_count2 = train_test[train_test['C5'] != 0].groupby(col)['C5'].count()\n",
    "    train_transaction[col+'_C5count'] = train_transaction[col].map(col_count2) / (train_transaction[col].map(col_count1) + 0.01)\n",
    "    test_transaction[col+'_C5count'] = test_transaction[col].map(col_count2) / (test_transaction[col].map(col_count1) + 0.01)\n",
    "    \n",
    "del train_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = pd.read_csv('../../data/input/train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('../../data/input/test_identity.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V126 24875\n",
      "V127 104743\n",
      "V128 46447\n",
      "V129 6555\n",
      "V130 72061\n",
      "V131 24989\n",
      "V132 9116\n",
      "V133 14910\n",
      "V134 11134\n",
      "V135 9184\n",
      "V136 14824\n",
      "V137 10682\n",
      "V160 10836\n",
      "V164 597\n",
      "V165 3440\n",
      "V166 2347\n",
      "V202 16120\n",
      "V203 20278\n",
      "V204 18198\n",
      "V205 6335\n",
      "V206 4711\n",
      "V207 8867\n",
      "V208 9699\n",
      "V209 10061\n",
      "V210 9836\n",
      "V211 10131\n",
      "V212 11253\n",
      "V213 10710\n",
      "V214 4277\n",
      "V215 5191\n",
      "V216 4769\n",
      "V263 16586\n",
      "V264 20089\n",
      "V265 18161\n",
      "V266 6651\n",
      "V267 10219\n",
      "V268 8347\n",
      "V270 7868\n",
      "V271 8110\n",
      "V272 7959\n",
      "V273 9401\n",
      "V274 11959\n",
      "V275 9821\n",
      "V276 4398\n",
      "V277 5417\n",
      "V278 4856\n",
      "V306 37081\n",
      "V307 140538\n",
      "V308 67074\n",
      "V309 14366\n",
      "V310 99482\n",
      "V311 8764\n",
      "V312 40465\n",
      "V313 43009\n",
      "V314 50538\n",
      "V315 44021\n",
      "V316 15081\n",
      "V317 24841\n",
      "V318 18718\n",
      "V319 10762\n",
      "V320 18664\n",
      "V321 13113\n"
     ]
    }
   ],
   "source": [
    "col_del = []\n",
    "for i in range(339):\n",
    "    col = \"V\" + str(i+1)\n",
    "    s = train_transaction[col].fillna(0).map(lambda x:0 if x%1 == 0 else 1).sum()\n",
    "    if s > 100:\n",
    "        print(col,s)\n",
    "        col_del.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 468)\n",
      "(506691, 467)\n"
     ]
    }
   ],
   "source": [
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "y_train = train['isFraud'].copy()\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "# Drop target, fill in NaNs\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "# Label Encoding\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "        X_test[f] = lbl.transform(list(X_test[f].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 829.86 MB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Categorical is not ordered for operation min\nyou can use .as_ordered() to change the Categorical to an ordered one\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-150d3612fda5>\u001b[0m in \u001b[0;36mreduce_mem_usage\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcol_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mc_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mc_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   9611\u001b[0m                                       skipna=skipna)\n\u001b[1;32m   9612\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0;32m-> 9613\u001b[0;31m                             numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m   9614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9615\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   3223\u001b[0m         return delegate._reduce(op=op, name=name, axis=axis, skipna=skipna,\n\u001b[1;32m   3224\u001b[0m                                 \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m                                 filter_type=filter_type, **kwds)\n\u001b[0m\u001b[1;32m   3226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   2066\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Categorical cannot perform the operation {op}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   2082\u001b[0m         \u001b[0mmin\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \"\"\"\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_for_ordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m             \u001b[0mgood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_codes\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mcheck_for_ordered\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             raise TypeError(\"Categorical is not ordered for operation {op}\\n\"\n\u001b[1;32m   1471\u001b[0m                             \u001b[0;34m\"you can use .as_ordered() to change the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                             \"Categorical to an ordered one\\n\".format(op=op))\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_values_for_argsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Categorical is not ordered for operation min\nyou can use .as_ordered() to change the Categorical to an ordered one\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "# WARNING! THIS CAN DAMAGE THE DATA \n",
    "\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "debug = False\n",
    "if debug:\n",
    "    split_pos = X_train.shape[0]*4//5\n",
    "    y_test = y_train.iloc[split_pos:]\n",
    "    y_train = y_train.iloc[:split_pos]\n",
    "    X_test = X_train.iloc[split_pos:,:]\n",
    "    X_train = X_train.iloc[:split_pos,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields ProductCD, card4, card6, P_emaildomain, R_emaildomain, M1, M2, M3, M4, M5, M6, M7, M8, M9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 726\u001b[0;31m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    378\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    379\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    237\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    238\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields ProductCD, card4, card6, P_emaildomain, R_emaildomain, M1, M2, M3, M4, M5, M6, M7, M8, M9"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "    i+=1\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=700,\n",
    "        max_depth=9,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        tree_method='gpu_hist'\n",
    "    )\n",
    "    \n",
    "    X_tr = X_train.iloc[tr_idx, :]\n",
    "    y_tr = y_train.iloc[tr_idx]\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    del X_tr\n",
    "    y_preds+= clf.predict_proba(X_test)[:,1] / folds\n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, clf.predict_proba(X_test)[:,1] / folds)) \n",
    "    del clf\n",
    "        \n",
    "    \n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in X_train.columns if x not in col_del]\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_preds11 = np.zeros(X_test.shape[0])\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "    i+=1\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=800,\n",
    "        max_depth=9,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        tree_method='gpu_hist'\n",
    "    )\n",
    "    \n",
    "    X_tr = X_train[features].iloc[tr_idx, :]\n",
    "    y_tr = y_train.iloc[tr_idx]\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    del X_tr\n",
    "    y_preds11+= clf.predict_proba(X_test[features])[:,1] / folds\n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, clf.predict_proba(X_test[features])[:,1] / folds))   \n",
    "    del clf\n",
    "    \n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds11))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds11*0.5 + y_preds*0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "cate = [x for x in X_train.columns if (x == 'ProductCD' or  x.startswith(\"addr\") or x.startswith(\"card\") or \n",
    "                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") ]\n",
    "print(cate)\n",
    "params = {'application': 'binary',\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'auc',\n",
    "          'max_depth': 16,\n",
    "          'learning_rate': 0.05,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'feature_fraction': 0.9,\n",
    "          'verbosity': -1,\n",
    "          'lambda_l1': 0.1,\n",
    "          'lambda_l2': 0.01,\n",
    "          'num_leaves': 500,\n",
    "          'min_child_weight': 3,\n",
    "          'data_random_seed': 17,\n",
    "         'nthreads':4}\n",
    "\n",
    "early_stop = 500\n",
    "verbose_eval = 30\n",
    "num_rounds = 600\n",
    "# \n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_preds2 = np.zeros(X_test.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "\n",
    "    \n",
    "    X_tr = X_train.iloc[tr_idx, :]\n",
    "    y_tr = y_train.iloc[tr_idx]\n",
    "    d_train = lgb.Dataset(X_tr, label=y_tr,categorical_feature = cate)\n",
    "    watchlist = []\n",
    "    if debug:\n",
    "        d_test = lgb.Dataset(X_test, label=y_test,categorical_feature = cate)\n",
    "        watchlist.append(d_test)\n",
    "    \n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval)\n",
    "        \n",
    "    \n",
    "    y_preds2+= model.predict(X_test) / folds\n",
    "    \n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = X_tr.columns\n",
    "    fold_importance_df[\"importance\"] = model.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = i + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, model.predict(X_test) / folds))  \n",
    "    i+=1\n",
    "    del X_tr,d_train\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds2))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2)*0.5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds2))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2)*0.5)) \n",
    "\n",
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:100].index)\n",
    "print(cols)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"Feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "\n",
    "\n",
    "features = [x for x in X_train.columns]\n",
    "\n",
    "cate = [x for x in X_train.columns if (x == 'ProductCD' or x in ['card1','card2'] or x.startswith(\"addr\") or \n",
    "                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") and not x == \"id_11\" ]\n",
    "\n",
    "# cate = []\n",
    "print(cate)\n",
    "verbose_eval = 30\n",
    "num_rounds = 800\n",
    "\n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed+1)\n",
    "y_preds3 = np.zeros(X_test.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "\n",
    "    \n",
    "    X_tr = X_train[features].iloc[tr_idx, :].fillna(-1)\n",
    "    y_tr = y_train.iloc[tr_idx]\n",
    "    \n",
    "    model=cb.CatBoostClassifier(iterations=num_rounds,depth=14,learning_rate=0.04,loss_function='Logloss',eval_metric='Logloss'\n",
    "                                ,task_type = \"GPU\")\n",
    "    if debug:\n",
    "        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n",
    "    else:\n",
    "        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n",
    "        \n",
    "\n",
    "    del X_tr\n",
    "    y_preds3+= model.predict_proba(X_test[features].fillna(-1))[:,1] / folds\n",
    "    \n",
    "    \n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, model.predict_proba(X_test[features].fillna(-1))[:,1] / folds))  \n",
    "    i+=1\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds3))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds3)*0.5))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2 + y_preds3)*0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds))\n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds2))\n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds3))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds3)*0.5))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2 + y_preds3*0.5)*0.33))\n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds11*0.5 + y_preds*0.5 + y_preds2 + y_preds3*0.5)*0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not debug:   \n",
    "    sample_submission['isFraud'] = (y_preds11*0.5 + y_preds*0.5 + y_preds2 + y_preds3*0.5)*0.33\n",
    "    sample_submission.to_csv('../../data/submit/simple_ensemble6.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
